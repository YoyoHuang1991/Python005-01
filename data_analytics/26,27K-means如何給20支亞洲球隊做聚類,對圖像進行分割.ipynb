{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "failing-johnston",
   "metadata": {},
   "source": [
    "K-means是非監督學習，解決聚類問題\n",
    "====\n",
    "K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。\n",
    "\n",
    "那么请你和我思考以下三个问题：\n",
    "* 如何确定 K 类的中心点？\n",
    "* 如何将其他点划分到 K 类中？\n",
    "* 如何区分 K-Means 与 KNN？\n",
    "\n",
    "如果理解了上面这 3 个问题，那么对 K-Means 的原理掌握得也就差不多了。\n",
    "\n",
    "先请你和我思考一个场景，假设我有 20 支亚洲足球队，想要将它们按照成绩划分成 3 个等级，可以怎样划分？\n",
    "\n",
    "K-Means的工作原理\n",
    "====\n",
    "对亚洲足球队的水平，你可能也有自己的判断。比如一流的亚洲球队有谁？你可能会说伊朗或韩国。二流的亚洲球队呢？你可能说是中国。三流的亚洲球队呢？你可能会说越南。\n",
    "\n",
    "其实这些都是靠我们的经验来划分的，那么伊朗、中国、越南可以说是三个等级的典型代表，也就是我们每个类的中心点。\n",
    "\n",
    "所以回过头来，如何确定 K 类的中心点？一开始我们是可以随机指派的，当你确认了中心点后，就可以按照距离将其他足球队划分到不同的类别中。\n",
    "\n",
    "这也就是 K-Means 的中心思想，就是这么简单直接。你可能会问：如果一开始，选择一流球队是中国，二流球队是伊朗，三流球队是韩国，中心点选择错了怎么办？其实不用担心，K-Means 有自我纠正机制，在不断的迭代过程中，会纠正中心点。中心点在整个迭代过程中，并不是唯一的，只是你需要一个初始值，一般算法会随机设置初始的中心点。\n",
    "\n",
    "好了，那我来把 K-Means 的工作原理给你总结下：\n",
    "1. 选取 K 个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的；\n",
    "2. 将每个点分配到最近的类中心点，这样就形成了 K 个类，然后重新计算每个类的中心点；\n",
    "3. 重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束。\n",
    "\n",
    "如何给亚洲球队做聚类\n",
    "====\n",
    "对于机器来说需要数据才能判断类中心点，所以我整理了 2015-2019 年亚洲球队的排名，如下表所示。\n",
    "\n",
    "其中 2019 年国际足联的世界排名，2015 年亚洲杯排名均为实际排名。2018 年世界杯中，很多球队没有进入到决赛圈，所以只有进入到决赛圈的球队才有实际的排名。如果是亚洲区预选赛 12 强的球队，排名会设置为 40。如果没有进入亚洲区预选赛 12 强，球队排名会设置为 50。\n",
    "<img src=\"./images/26-01.png\">\n",
    "\n",
    "针对上面的排名，我们首先需要做的是数据规范化。你可以把这些值划分到[0,1]或者按照均值为 0，方差为 1 的正态分布进行规范化。具体数据规范化的步骤可以看下 13 篇，也就是数据变换那一篇。\n",
    "\n",
    "我先把数值都规范化到[0,1]的空间中，得到了以下的数值表：\n",
    "<img src=\"./images/26-02.png\">\n",
    "如果我们随机选取中国、日本、韩国为三个类的中心点，我们就需要看下这些球队到中心点的距离。\n",
    "\n",
    "距离有多种计算的方式，有关距离的计算我在 KNN 算法中也讲到过：\n",
    "* 欧氏距离\n",
    "* 曼哈顿距离\n",
    "* 切比雪夫距离\n",
    "* 余弦距离\n",
    "\n",
    "欧氏距离是最常用的距离计算方式，这里我选择欧氏距离作为距离的标准，计算每个队伍分别到中国、日本、韩国的距离，然后根据距离远近来划分。我们看到大部分的队，会和中国队聚类到一起。这里我整理了距离的计算过程，比如中国和中国的欧氏距离为 0，中国和日本的欧式距离为 0.732003。如果按照中国、日本、韩国为 3 个分类的中心点，欧氏距离的计算结果如下表所示：\n",
    "<img src=\"./images/26-03.png\">\n",
    "\n",
    "然后我们再重新计算这三个类的中心点，如何计算呢？最简单的方式就是取平均值，然后根据新的中心点按照距离远近重新分配球队的分类，再根据球队的分类更新中心点的位置。计算过程这里不展开，最后一直迭代（重复上述的计算过程：计算中心点和划分分类）到分类不再发生变化，可以得到以下的分类结果：\n",
    "<img src=\"./images/26-04.png\">\n",
    "所以我们能看出来第一梯队有日本、韩国、伊朗、沙特、澳洲；第二梯队有中国、伊拉克、阿联酋、乌兹别克斯坦；第三梯队有卡塔尔、泰国、越南、阿曼、巴林、朝鲜、印尼、叙利亚、约旦、科威特和巴勒斯坦。\n",
    "\n",
    "如何使用sklearn中的K-Means算法\n",
    "====\n",
    "sklearn 是 Python 的机器学习工具库，如果从功能上来划分，sklearn 可以实现分类、聚类、回归、降维、模型选择和预处理等功能。这里我们使用的是 sklearn 的聚类函数库，因此需要引用工具包，具体代码如下：\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "```\n",
    "当然 K-Means 只是 sklearn.cluster 中的一个聚类库，实际上包括 K-Means 在内，sklearn.cluster 一共提供了 9 种聚类方法，比如 Mean-shift，DBSCAN，Spectral clustering（谱聚类）等。这些聚类方法的原理和 K-Means 不同，这里不做介绍。K-Means 如何创建：\n",
    "```python\n",
    "KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')\n",
    "```\n",
    "我们能看到在 K-Means 类创建的过程中，有一些主要的参数：\n",
    "* n_clusters: 即 K 值，一般需要多试一些 K 值来保证更好的聚类效果。你可以随机设置一些 K 值，然后选择聚类效果最好的作为最终的 K 值；\n",
    "* max_iter： 最大迭代次数，如果聚类很难收敛的话，设置最大迭代次数可以让我们及时得到反馈结果，否则程序运行时间会非常长；\n",
    "* n_init：初始化中心点的运算次数，默认是 10。程序是否能快速收敛和中心点的选择关系非常大，所以在中心点选择上多花一些时间，来争取整体时间上的快速收敛还是非常值得的。由于每一次中心点都是随机生成的，这样得到的结果就有好有坏，非常不确定，所以要运行 n_init 次, 取其中最好的作为初始的中心点。如果 **K 值比较大**的时候，你可以适当增大 n_init 这个值；\n",
    "* init： 即初始值选择的方式，默认是采用优化过的 k-means++ 方式，你也可以自己指定中心点，或者采用 random 完全随机的方式。自己设置中心点一般是对于个性化的数据进行设置，很少采用。random 的方式则是完全随机的方式，一般推荐采用优化过的 k-means++ 方式；\n",
    "* algorithm：k-means 的实现算法，有“auto” “full”“elkan”三种。一般来说建议直接用默认的\"auto\"。简单说下这三个取值的区别，如果你选择\"full\"采用的是传统的 K-Means 算法，“auto”会根据数据的特点自动选择是选择“full”还是“elkan”。我们一般选择默认的取值，即“auto” 。\n",
    "\n",
    "在创建好 K-Means 类之后，就可以使用它的方法，最常用的是 fit 和 predict 这个两个函数。你可以单独使用 fit 函数和 predict 函数，也可以合并使用 fit_predict 函数。其中 fit(data) 可以对 data 数据进行 k-Means 聚类。 predict(data) 可以针对 data 中的每个样本，计算最近的类。\n",
    "\n",
    "现在我们要完整地跑一遍 20 支亚洲球队的聚类问题。我把数据上传到了GitHub上，你可以自行下载。\n",
    "```python\n",
    "# coding: utf-8\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 输入数据\n",
    "data = pd.read_csv('data.csv', encoding='gbk')\n",
    "train_x = data[[\"2019年国际排名\",\"2018世界杯\",\"2015亚洲杯\"]]\n",
    "df = pd.DataFrame(train_x)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "# 规范化到[0,1]空间\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "train_x=min_max_scaler.fit_transform(train_x)\n",
    "# kmeans算法\n",
    "kmeans.fit(train_x)\n",
    "predict_y = kmeans.predict(train_x)\n",
    "# 合并聚类结果，插入到原数据中\n",
    "result = pd.concat((data,pd.DataFrame(predict_y)),axis=1)\n",
    "result.rename({0:u'聚类'},axis=1,inplace=True)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "总结\n",
    "====\n",
    "今天我给你讲了 K-Means 算法原理，我们再来看下开篇我给你提的三个问题。\n",
    "\n",
    "如何确定 K 类的中心点？其中包括了初始的设置，以及中间迭代过程中中心点的计算。在初始设置中，会进行 n_init 次的选择，然后选择初始中心点效果最好的为初始值。在每次分类更新后，你都需要重新确认每一类的中心点，一般采用均值的方式进行确认。\n",
    "\n",
    "如何将其他点划分到 K 类中？这里实际上是关于距离的定义，我们知道距离有多种定义的方式，在 K-Means 和 KNN 中，我们都可以采用**欧氏距离、曼哈顿距离、切比雪夫距离、余弦距离等**。对于点的划分，就看它离哪个类的中心点的距离最近，就属于哪一类。\n",
    "\n",
    "## 如何区分 K-Means 和 KNN 这两种算法呢？\n",
    "刚学过 K-Means 和 KNN 算法的同学应该能知道两者的区别，但往往过了一段时间，就容易混淆。所以我们可以从三个维度来区分 K-Means 和 KNN 这两个算法：\n",
    "* 首先，这两个算法解决数据挖掘的两类问题。K-Means 是聚类算法，KNN 是分类算法。\n",
    "* 这两个算法分别是两种不同的学习方式。K-Means 是非监督学习，也就是不需要事先给出分类标签，而 KNN 是有监督学习，需要我们给出训练数据的分类标识。\n",
    "* 最后，K 值的含义不同。K-Means 中的 K 值代表 K 类。KNN 中的 K 值代表 K 个最接近的邻居。\n",
    "<img src=\"./images/26-05.png\">\n",
    "\n",
    "### 1. 那么学完了今天的内容后，你能说一下 K-Means 的算法原理吗？\n",
    "### 2. 如果我们把上面的 20 支亚洲球队用 K-Means 划分成 5 类，在规范化数据的时候采用标准化的方式（即均值为 0，方差为 1），该如何编写程序呢？运行的结果又是如何？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-priority",
   "metadata": {},
   "source": [
    "K-means如何使用K-means對圖像進行分割\n",
    "====\n",
    "图像分割就是利用图像自身的信息，比如颜色、纹理、形状等特征进行划分，**将图像分割成不同的区域**，划分出来的每个区域就相当于是对图像中的像素进行了聚类。单个区域内的像素之间的**相似度大**，不同区域间的像素差异性大。这个特性正好符合聚类的特性，所以你可以把图像分割看成是将图像中的信息进行聚类。当然聚类只是分割图像的一种方式，除了聚类，我们还可以基于图像**颜色的阈值**进行分割，或者基于**图像边缘**的信息进行分割等。\n",
    "\n",
    "## 將微信開屏封面進行分割\n",
    "上节课，我讲了 sklearn 工具包中的 K-Means 算法使用，我们现在用 K-Means 算法对微信页面进行分割。微信开屏图如下所示：\n",
    "<img src=\"./images/26-06.png\">\n",
    "我们先设定下聚类的流程，聚类的流程和分类差不多，如图所示：\n",
    "<img src=\"./images/26-07.jpg\">\n",
    "在准备阶段里，我们需要对数据进行加载。因为处理的是图像信息，我们除了要获取图像数据以外，还需要获取图像的尺寸和通道数，然后基于图像中每个通道的数值进行数据规范化。这里我们需要定义个函数 load_data，来帮我们进行图像加载和数据规范化。代码如下：\n",
    "```python\n",
    "# 加载图像，并对数据进行规范化\n",
    "def load_data(filePath):\n",
    "    # 读文件\n",
    "    f = open(filePath,'rb')\n",
    "    data = []\n",
    "    # 得到图像的像素值\n",
    "    img = image.open(f)\n",
    "    # 得到图像尺寸\n",
    "    width, height = img.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # 得到点(x,y)的三个通道值\n",
    "            c1, c2, c3 = img.getpixel((x, y))\n",
    "            data.append([c1, c2, c3])\n",
    "    f.close()\n",
    "    # 采用Min-Max规范化\n",
    "    mm = preprocessing.MinMaxScaler()\n",
    "    data = mm.fit_transform(data)\n",
    "    return np.mat(data), width, height\n",
    "```\n",
    "因为 jpg 格式的图像是三个通道 (R,G,B)，也就是一个像素点具有 3 个特征值。这里我们用 c1、c2、c3 来获取平面坐标点 (x,y) 的三个特征值，特征值是在 0-255 之间。\n",
    "\n",
    "为了加快聚类的收敛，我们需要采用 Min-Max 规范化对数据进行规范化。我们定义的 load_data 函数返回的结果包括了针对 (R,G,B) 三个通道规范化的数据，以及图像的尺寸信息。在定义好 load_data 函数后，我们直接调用就可以得到相关信息，代码如下：\n",
    "```python\n",
    "# 加载图像，得到规范化的结果img，以及图像尺寸\n",
    "img, width, height = load_data('./weixin.jpg')\n",
    "```\n",
    "假设我们想要对图像分割成 2 部分，在聚类阶段，我们可以将聚类数设置为 2，这样图像就自动聚成 2 类。代码如下：\n",
    "```python\n",
    "# 用K-Means对图像进行2聚类\n",
    "kmeans =KMeans(n_clusters=2)\n",
    "kmeans.fit(img)\n",
    "label = kmeans.predict(img)\n",
    "# 将图像聚类结果，转化成图像尺寸的矩阵\n",
    "label = label.reshape([width, height])\n",
    "# 创建个新图像pic_mark，用来保存图像聚类的结果，并设置不同的灰度值\n",
    "pic_mark = image.new(\"L\", (width, height))\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        # 根据类别设置图像灰度, 类别0 灰度值为255， 类别1 灰度值为127\n",
    "        pic_mark.putpixel((x, y), int(256/(label[x][y]+1))-1)\n",
    "pic_mark.save(\"weixin_mark.jpg\", \"JPEG\")\n",
    "```\n",
    "代码中有一些参数，我来给你讲解一下这些参数的作用和设置方法。\n",
    "\n",
    "我们使用了 fit 和 predict 这两个函数来做数据的训练拟合和预测，因为传入的参数是一样的，我们可以同时进行 fit 和 predict 操作，这样我们可以直接使用 fit_predict(data) 得到聚类的结果。得到聚类的结果 label 后，实际上是一个一维的向量，我们需要把它转化成图像尺寸的矩阵。label 的聚类结果是从 0 开始统计的，当聚类数为 2 的时候，聚类的标识 label=0 或者 1。\n",
    "\n",
    "如果你想对图像聚类的结果进行可视化，直接看 0 和 1 是看不出来的，还需要将 0 和 1 转化为灰度值。灰度值一般是在 0-255 的范围内，我们可以将 label=0 设定为灰度值 255，label=1 设定为灰度值 127。具体方法是用 int(256/(label[x][y]+1))-1。可视化的时候，主要是通过设置图像的灰度值进行显示。所以我们把聚类 label=0 的像素点都统一设置灰度值为 255，把聚类 label=1 的像素点都统一设置灰度值为 127。原来图像的灰度值是在 0-255 之间，现在就只有 2 种颜色（也就是灰度为 255，和灰度 127）。\n",
    "\n",
    "有了这些灰度信息，我们就可以用 image.new 创建一个新的图像，用 putpixel 函数对新图像的点进行灰度值的设置，最后用 save 函数保存聚类的灰度图像。这样你就可以看到聚类的可视化结果了，如下图所示：\n",
    "<img src=\"./images/26-08.png\">\n",
    "\n",
    "上面是分割成 2 个部分的分割可视化，完整代码见这里。\n",
    "\n",
    "如果我们想要分割成 16 个部分，该如何对不同分类设置不同的颜色值呢？这里需要用到 skimage 工具包，它是图像处理工具包。你需要使用 pip install scikit-image 来进行安装。\n",
    "\n",
    "这段代码可以将聚类标识矩阵转化为不同颜色的矩阵：\n",
    "```python\n",
    "from skimage import color\n",
    "# 将聚类标识矩阵转化为不同颜色的矩阵\n",
    "label_color = (color.label2rgb(label)*255).astype(np.uint8)\n",
    "label_color = label_color.transpose(1,0,2)\n",
    "images = image.fromarray(label_color)\n",
    "images.save('weixin_mark_color.jpg')\n",
    "```\n",
    "代码中，我使用 skimage 中的 label2rgb 函数来将 label 分类标识转化为颜色数值，因为我们的颜色值范围是[0,255]，所以还需要乘以 255 进行转化，最后再转化为 np.uint8 类型。unit8 类型代表无符号整数，范围是 0-255 之间。\n",
    "\n",
    "得到颜色矩阵后，你可以把它输出出来，这时你发现输出的图像是颠倒的，原因可能是图像源拍摄的时候本身是倒置的。我们需要设置三维矩阵的转置，让第一维和第二维颠倒过来，也就是使用 transpose(1,0,2)，将原来的 (0,1,2）顺序转化为 (1,0,2) 顺序，即第一维和第二维互换。\n",
    "\n",
    "最后我们使用 fromarray 函数，它可以通过矩阵来生成图片，并使用 save 进行保存。最后得到的分类标识颜色化图像是这样的：\n",
    "<img src=\"./images/26-09.png\">\n",
    "\n",
    "刚才我们做的是聚类的可视化。如果我们想要看到对应的原图，可以将每个簇（即每个类别）的点的 RGB 值设置为该簇质心点的 RGB 值，也就是簇内的点的特征均为质心点的特征。\n",
    "### 見下方第二個cell\n",
    "\n",
    "我给出了完整的代码，代码中，我可以把范围为 0-255 的数值投射到 1-256 数值之间，方法是对每个数值进行加 1，你可以自己来运行下：\n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "# 使用K-means对图像进行聚类，并显示聚类压缩后的图像\n",
    "import numpy as np\n",
    "import PIL.Image as image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.image as mpimg\n",
    "# 加载图像，并对数据进行规范化\n",
    "def load_data(filePath):\n",
    "    # 读文件\n",
    "    f = open(filePath,'rb')\n",
    "    data = []\n",
    "    # 得到图像的像素值\n",
    "    img = image.open(f)\n",
    "    # 得到图像尺寸\n",
    "    width, height = img.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # 得到点(x,y)的三个通道值\n",
    "            c1, c2, c3 = img.getpixel((x, y))\n",
    "            data.append([(c1+1)/256.0, (c2+1)/256.0, (c3+1)/256.0])\n",
    "    f.close()\n",
    "    return np.mat(data), width, height\n",
    "# 加载图像，得到规范化的结果imgData，以及图像尺寸\n",
    "img, width, height = load_data('./weixin.jpg')\n",
    "# 用K-Means对图像进行16聚类\n",
    "kmeans =KMeans(n_clusters=16)\n",
    "label = kmeans.fit_predict(img)\n",
    "# 将图像聚类结果，转化成图像尺寸的矩阵\n",
    "label = label.reshape([width, height])\n",
    "# 创建个新图像img，用来保存图像聚类压缩后的结果\n",
    "img=image.new('RGB', (width, height))\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        c1 = kmeans.cluster_centers_[label[x, y], 0]\n",
    "        c2 = kmeans.cluster_centers_[label[x, y], 1]\n",
    "        c3 = kmeans.cluster_centers_[label[x, y], 2]\n",
    "        img.putpixel((x, y), (int(c1*256)-1, int(c2*256)-1, int(c3*256)-1))\n",
    "img.save('weixin_new.jpg')\n",
    "```\n",
    "\n",
    "你可以看到我没有用到 sklearn 自带的 MinMaxScaler，而是自己写了 Min-Max 规范化的公式。这样做的原因是我们知道 RGB 每个通道的数值在[0,255]之间，所以我们可以用每个通道的数值 +1/256，这样数值就会在[0,1]之间。\n",
    "\n",
    "对图像做了 Min-Max 空间变换之后，还可以对其进行反变换，还原出对应原图的通道值。\n",
    "\n",
    "对于点 (x,y)，我们找到它们所属的簇 label[x,y]，然后得到这个簇的质心特征，用 c1,c2,c3 表示：\n",
    "```python\n",
    "c1 = kmeans.cluster_centers_[label[x, y], 0]\n",
    "c2 = kmeans.cluster_centers_[label[x, y], 1]\n",
    "c3 = kmeans.cluster_centers_[label[x, y], 2]\n",
    "```\n",
    "因为 c1, c2, c3 对应的是数据规范化的数值，因此我们还需要进行反变换，即：\n",
    "```python\n",
    "c1=int(c1*256)-1\n",
    "c2=int(c2*256)-1\n",
    "c3=int(c3*256)-1\n",
    "```\n",
    "然后用 img.putpixel 设置点 (x,y) 反变换后得到的特征值。最后用 img.save 保存图像。\n",
    "\n",
    "总结\n",
    "====\n",
    "今天我们用 K-Means 做了图像的分割，其实不难发现 K-Means 聚类有个缺陷：聚类个数 K 值需要事先指定。如果你不知道该聚成几类，那么最好会给 K 值多设置几个，然后选择聚类结果最好的那个值。\n",
    "\n",
    "通过今天的图像分割，你发现用 K-Means 计算的过程在 sklearn 中就是几行代码，大部分的工作还是在预处理和后处理上。预处理是将图像进行加载，数据规范化。后处理是对聚类后的结果进行反变换。\n",
    "\n",
    "如果涉及到后处理，你可以自己来设定数据规范化的函数，这样反变换的函数比较容易编写。\n",
    "\n",
    "另外我们还学习了如何在 Python 中如何对图像进行读写，具体的代码如下，上文中也有相应代码，你也可以自己对应下：\n",
    "```python\n",
    "import PIL.Image as image\n",
    "# 得到图像的像素值\n",
    "img = image.open(f)\n",
    "# 得到图像尺寸\n",
    "width, height = img.size\n",
    "```\n",
    "这里会使用 PIL 这个工具包，它的英文全称叫 Python Imaging Library，顾名思义，它是 Python 图像处理标准库。同时我们也使用到了 skimage 工具包（scikit-image），它也是图像处理工具包。用过 Matlab 的同学知道，Matlab 处理起图像来非常方便。skimage 可以和它相媲美，集成了很多图像处理函数，其中对不同分类标识显示不同的颜色。在 Python 中图像处理工具包，我们用的是 skimage 工具包。\n",
    "\n",
    "这节课没有太多的理论概念，主要讲了 K-Means 聚类工具，数据规范化工具，以及图像处理工具的使用，并在图像分割中进行运用。其中涉及到的工具包比较多，你需要在练习的时候多加体会。当然不同尺寸的图像，K-Means 运行的时间也是不同的。如果图像尺寸比较大，你可以事先进行压缩，长宽在 200 像素内运行速度会比较快，如果超过了 1000 像素，速度会很慢。\n",
    "<img src=\"./images/26-10.png\">\n",
    "\n",
    "今天我讲了如何使用 K-Means 聚类做图像分割，谈谈你使用的体会吧。另外我在GitHub上上传了一张 baby.jpg 的图片，请你编写代码用 K-Means 聚类方法将它分割成 16 个部分。\n",
    "<img src=\"./images/26-11_baby.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 使用K-means对图像进行聚类，显示分割标识的可视化\n",
    "import numpy as np\n",
    "import PIL.Image as image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 加载图像，并对数据进行规范化\n",
    "def load_data(filePath):\n",
    "    # 读文件\n",
    "    f = open(filePath,'rb')\n",
    "    data = []\n",
    "    # 得到图像的像素值\n",
    "    img = image.open(f)\n",
    "    # 得到图像尺寸\n",
    "    width, height = img.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # 得到点(x,y)的三个通道值\n",
    "            c1, c2, c3 = img.getpixel((x, y))\n",
    "            data.append([c1, c2, c3])\n",
    "    f.close()\n",
    "    # 采用Min-Max规范化\n",
    "    mm = preprocessing.MinMaxScaler()\n",
    "    data = mm.fit_transform(data)\n",
    "    return np.mat(data), width, height\n",
    "\n",
    "# 加载图像，得到规范化的结果img，以及图像尺寸\n",
    "img, width, height = load_data('./weixin.jpg')\n",
    "\n",
    "# 用K-Means对图像进行2聚类\n",
    "kmeans =KMeans(n_clusters=2)\n",
    "kmeans.fit(img)\n",
    "label = kmeans.predict(img)\n",
    "# 将图像聚类结果，转化成图像尺寸的矩阵\n",
    "label = label.reshape([width, height])\n",
    "# 创建个新图像pic_mark，用来保存图像聚类的结果，并设置不同的灰度值\n",
    "pic_mark = image.new(\"L\", (width, height))\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        # 根据类别设置图像灰度, 类别0 灰度值为255， 类别1 灰度值为127\n",
    "        pic_mark.putpixel((x, y), int(256/(label[x][y]+1))-1)\n",
    "pic_mark.save(\"weixin_mark.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 使用K-means对图像进行聚类，显示分割标识的可视化\n",
    "import numpy as np\n",
    "import PIL.Image as image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from skimage import color\n",
    "\n",
    "# 加载图像，并对数据进行规范化\n",
    "def load_data(filePath):\n",
    "    # 读文件\n",
    "    f = open(filePath,'rb')\n",
    "    data = []\n",
    "    # 得到图像的像素值\n",
    "    img = image.open(f)\n",
    "    # 得到图像尺寸\n",
    "    width, height = img.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # 得到点(x,y)的三个通道值\n",
    "            c1, c2, c3 = img.getpixel((x, y))\n",
    "            data.append([c1, c2, c3])\n",
    "    f.close()\n",
    "    # 采用Min-Max规范化\n",
    "    mm = preprocessing.MinMaxScaler()\n",
    "    data = mm.fit_transform(data)\n",
    "    return np.mat(data), width, height\n",
    "\n",
    "# 加载图像，得到规范化的结果img，以及图像尺寸\n",
    "img, width, height = load_data('./weixin.jpg')\n",
    "\n",
    "# 用K-Means对图像进行16聚类\n",
    "kmeans =KMeans(n_clusters=16)\n",
    "kmeans.fit(img)\n",
    "label = kmeans.predict(img)\n",
    "# 将图像聚类结果，转化成图像尺寸的矩阵\n",
    "label = label.reshape([width, height])\n",
    "# 将聚类标识矩阵转化为不同颜色的矩阵\n",
    "label_color = (color.label2rgb(label)*255).astype(np.uint8)\n",
    "label_color = label_color.transpose(1,0,2)\n",
    "images = image.fromarray(label_color)\n",
    "images.save('weixin_mark_color.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# 使用K-means对图像进行聚类，并显示聚类压缩后的图像\n",
    "import numpy as np\n",
    "import PIL.Image as image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.image as mpimg\n",
    "# 加载图像，并对数据进行规范化\n",
    "def load_data(filePath):\n",
    "    # 读文件\n",
    "    f = open(filePath,'rb')\n",
    "    data = []\n",
    "    # 得到图像的像素值\n",
    "    img = image.open(f)\n",
    "    # 得到图像尺寸\n",
    "    width, height = img.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # 得到点(x,y)的三个通道值\n",
    "            c1, c2, c3 = img.getpixel((x, y))\n",
    "            data.append([(c1+1)/256.0, (c2+1)/256.0, (c3+1)/256.0])\n",
    "    f.close()\n",
    "    return np.mat(data), width, height\n",
    "# 加载图像，得到规范化的结果imgData，以及图像尺寸\n",
    "img, width, height = load_data('./weixin.jpg')\n",
    "# 用K-Means对图像进行16聚类\n",
    "kmeans =KMeans(n_clusters=16)\n",
    "label = kmeans.fit_predict(img)\n",
    "# 将图像聚类结果，转化成图像尺寸的矩阵\n",
    "label = label.reshape([width, height])\n",
    "# 创建个新图像img，用来保存图像聚类压缩后的结果\n",
    "img=image.new('RGB', (width, height))\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        c1 = kmeans.cluster_centers_[label[x, y], 0]\n",
    "        c2 = kmeans.cluster_centers_[label[x, y], 1]\n",
    "        c3 = kmeans.cluster_centers_[label[x, y], 2]\n",
    "        img.putpixel((x, y), (int(c1*256)-1, int(c2*256)-1, int(c3*256)-1))\n",
    "img.save('weixin_new.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
